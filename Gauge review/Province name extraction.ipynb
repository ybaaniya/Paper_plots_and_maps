{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import time\n",
    "from datetime import datetime\n",
    "import concurrent.futures\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from functools import lru_cache\n",
    "import openpyxl\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_requests_session(retries=3):\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=retries,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "# Cache results to avoid redundant API calls for similar coordinates\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_location_info_cached(lat, lon, username, session):\n",
    "    \"\"\"\n",
    "    Cached version of location lookup - rounds coordinates to reduce redundant calls\n",
    "    \"\"\"\n",
    "    # Round to 2 decimal places (about 1km precision) to increase cache hits\n",
    "    lat_rounded = round(float(lat), 2)\n",
    "    lon_rounded = round(float(lon), 2)\n",
    "    \n",
    "    return get_location_info(lat_rounded, lon_rounded, username, session)\n",
    "\n",
    "def get_location_info(lat, lon, username, session):\n",
    "    \"\"\"\n",
    "    Fetch location information from GeoNames API\n",
    "    Special handling for England and Scotland to use adminName2 instead of adminName1\n",
    "    \"\"\"\n",
    "    base_url = \"http://api.geonames.org/findNearbyJSON\"\n",
    "    params = {\n",
    "        'lat': lat,\n",
    "        'lng': lon,\n",
    "        'username': username,\n",
    "        'style': 'FULL',\n",
    "        'maxRows': 1\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = session.get(base_url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        if 'geonames' in data and data['geonames']:\n",
    "            location = data['geonames'][0]\n",
    "            \n",
    "            # Check if the country is England or Scotland\n",
    "            country_name = location.get('countryName', '')\n",
    "            if country_name in ['England', 'Scotland']:\n",
    "                # For England and Scotland, use adminName2 (county/council area)\n",
    "                return location.get('adminName2', 'Unknown')\n",
    "            else:\n",
    "                # For all other countries, use adminName1 (state/province)\n",
    "                return location.get('adminName1', 'Unknown')\n",
    "        return 'Not Found'\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f'Error: {str(e)}'\n",
    "\n",
    "def process_locations(input_file, username, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Process locations with missing State/Province/Territory data\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input CSV file\n",
    "        username (str): GeoNames API username\n",
    "        batch_size (int): Number of records to process per hour\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    print(f\"Loading data from {input_file}\")\n",
    "    df = pd.read_excel(input_file)\n",
    "    \n",
    "    # Create backup of original file\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    backup_file = f\"{input_file.rsplit('.', 1)[0]}_backup_{timestamp}.csv\"\n",
    "    df.to_csv(backup_file, index=False)\n",
    "    print(f\"Created backup at {backup_file}\")\n",
    "    \n",
    "    # Add new column for the API results\n",
    "    if 'state test' not in df.columns:\n",
    "        df['state test'] = None\n",
    "    \n",
    "    # Filter rows with empty state/province\n",
    "    mask = df['State/Province/Territory'].isna() | (df['State/Province/Territory'] == '')\n",
    "    rows_to_process = df[mask].copy()\n",
    "    \n",
    "    # Skip rows with missing coordinates\n",
    "    rows_to_process = rows_to_process.dropna(subset=['latitude', 'longitude'])\n",
    "    \n",
    "    total_rows = len(rows_to_process)\n",
    "    if total_rows == 0:\n",
    "        print(\"No rows to process\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"Found {total_rows} rows with missing State/Province/Territory\")\n",
    "    \n",
    "    # Create a persistent session for all requests\n",
    "    session = create_requests_session()\n",
    "    \n",
    "    # Process in batches with rate limiting\n",
    "    processed = 0\n",
    "    batch_start_time = time.time()\n",
    "    \n",
    "    # Create progress bar\n",
    "    with tqdm(total=total_rows, desc=\"Processing locations\", unit=\"loc\") as pbar:\n",
    "        for idx, row in rows_to_process.iterrows():\n",
    "            if processed > 0 and processed % batch_size == 0:\n",
    "                # Wait if we've hit the batch limit\n",
    "                elapsed = time.time() - batch_start_time\n",
    "                if elapsed < 3600:  # If less than an hour has passed\n",
    "                    sleep_time = 3600 - elapsed\n",
    "                    pbar.write(f\"Completed batch of {batch_size}. Waiting {sleep_time/60:.1f} minutes before next batch...\")\n",
    "                    time.sleep(sleep_time)\n",
    "                batch_start_time = time.time()\n",
    "                \n",
    "                # Save progress after each batch\n",
    "                progress_file = f\"{input_file.rsplit('.', 1)[0]}_progress_{timestamp}.csv\"\n",
    "                df.to_csv(progress_file, index=False)\n",
    "                pbar.write(f\"Saved progress at {processed}/{total_rows} rows\")\n",
    "            \n",
    "            # Get admin region from GeoNames\n",
    "            admin_name = get_location_info_cached(row['latitude'], row['longitude'], username, session)\n",
    "            \n",
    "            # Update the dataframe with the result\n",
    "            df.at[idx, 'state test'] = admin_name\n",
    "            \n",
    "            processed += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Small delay between API calls\n",
    "            time.sleep(0.2)\n",
    "    \n",
    "    # Save final results\n",
    "    output_file = f\"{input_file.rsplit('.', 1)[0]}_completed_{timestamp}.xlsx\"\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"\\nProcessing completed. Results saved to {output_file}\")\n",
    "    \n",
    "    # Cache statistics\n",
    "    print(f\"Cache info: {get_location_info_cached.cache_info()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    INPUT_FILE = '/Users/yubinbaaniya/Downloads/gauge_review_with_duplicate_and_main.xlsx'\n",
    "    GEONAMES_USERNAME = \"ybaaniya\"  # Your GeoNames username\n",
    "    BATCH_SIZE = 900  #API allows only 1000 request per hour\n",
    "    \n",
    "    try:\n",
    "        # Process the file\n",
    "        result_df = process_locations(INPUT_FILE, GEONAMES_USERNAME, BATCH_SIZE)\n",
    "        print(\"Processing completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
