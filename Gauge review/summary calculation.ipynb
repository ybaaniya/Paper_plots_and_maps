{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all the station that is in the folder called gauge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to process a single CSV file\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Remove negative values in streamflow\n",
    "        df = df[df['Streamflow (m3/s)'] >= 0]\n",
    "\n",
    "        if df.empty:\n",
    "            return None\n",
    "\n",
    "        # Extract the first and last dates\n",
    "        first_date = pd.to_datetime(df['Datetime']).min()\n",
    "        last_date = pd.to_datetime(df['Datetime']).max()\n",
    "\n",
    "        # Calculate number of possible days\n",
    "        num_possible_days = (last_date - first_date).days + 1\n",
    "\n",
    "        # Calculate number of daily measurements\n",
    "        num_daily_measurements = len(df)\n",
    "\n",
    "        # Calculate percentage of missing data\n",
    "        percent_missing = ((num_possible_days - num_daily_measurements) / num_possible_days) * 100\n",
    "\n",
    "        # Calculate flow statistics\n",
    "        average_flow = df['Streamflow (m3/s)'].mean()\n",
    "        min_flow = df['Streamflow (m3/s)'].min()\n",
    "        max_flow = df['Streamflow (m3/s)'].max()\n",
    "\n",
    "        # Calculate monthly observation counts across all years\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "        df['Month'] = df['Datetime'].dt.month_name()\n",
    "        monthly_counts = df['Month'].value_counts().reindex(\n",
    "            [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], fill_value=0\n",
    "        )\n",
    "\n",
    "        # Calculate non-zero monthly observation counts across all years\n",
    "        non_zero_monthly_counts = df[df['Streamflow (m3/s)'] > 0]['Month'].value_counts().reindex(\n",
    "            [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], fill_value=0\n",
    "        )\n",
    "\n",
    "        # Extract filename without extension\n",
    "        filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "        # Return the summary statistics\n",
    "        return {\n",
    "            \"Filename\": filename,\n",
    "            \"First Measurement Date\": first_date,\n",
    "            \"Last Measurement Date\": last_date,\n",
    "            \"Number of Possible Days\": num_possible_days,\n",
    "            \"Number of Daily Measurements\": num_daily_measurements,\n",
    "            \"% Missing\": percent_missing,\n",
    "            \"Average Flow (m3/s)\": average_flow,\n",
    "            \"Min Flow (m3/s)\": min_flow,\n",
    "            \"Max Flow (m3/s)\": max_flow,\n",
    "            **monthly_counts.add_suffix(\" (Total)\").to_dict(),\n",
    "            **non_zero_monthly_counts.add_suffix(\" (Non-Zero)\").to_dict()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main function to process all files in a folder\n",
    "def process_all_files(folder_path, output_file):\n",
    "    # List all CSV files in the folder\n",
    "    csv_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Wrap file processing with tqdm for a progress bar\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_file)(file) for file in tqdm(csv_files, desc=\"Processing Files\")\n",
    "    )\n",
    "\n",
    "    # Filter out None results\n",
    "    results = [res for res in results if res is not None]\n",
    "\n",
    "    # Create a summary dataframe\n",
    "    summary_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save the summary to a CSV file\n",
    "    summary_df.to_csv(output_file, index=False)\n",
    "    print(f\"Summary file saved to {output_file}\")\n",
    "\n",
    "# Specify the folder path and output file\n",
    "folder_path = \"/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/gauge_data\"\n",
    "output_file = \"/Users/yubinbaaniya/Documents/GAUGE REVIEW/summary_statistics.csv\"\n",
    "\n",
    "# Run the processing\n",
    "process_all_files(folder_path, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read and process only those stations in csv file for example for a certain country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to process a single CSV file\n",
    "def process_specific_file(file_path):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Remove negative values in streamflow\n",
    "        df = df[df['Streamflow (m3/s)'] >= 0]\n",
    "\n",
    "        if df.empty:\n",
    "            return None\n",
    "\n",
    "        # Extract the first and last dates\n",
    "        first_date = pd.to_datetime(df['Datetime']).min()\n",
    "        last_date = pd.to_datetime(df['Datetime']).max()\n",
    "\n",
    "        # Calculate number of possible days\n",
    "        num_possible_days = (last_date - first_date).days + 1\n",
    "\n",
    "        # Calculate number of daily measurements\n",
    "        num_daily_measurements = len(df)\n",
    "\n",
    "        # Calculate percentage of missing data\n",
    "        percent_missing = ((num_possible_days - num_daily_measurements) / num_possible_days) * 100\n",
    "\n",
    "        # Calculate flow statistics\n",
    "        average_flow = df['Streamflow (m3/s)'].mean()\n",
    "        min_flow = df['Streamflow (m3/s)'].min()\n",
    "        max_flow = df['Streamflow (m3/s)'].max()\n",
    "\n",
    "        # Calculate monthly observation counts across all years\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "        df['Month'] = df['Datetime'].dt.month_name()\n",
    "        monthly_counts = df['Month'].value_counts().reindex(\n",
    "            [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], fill_value=0\n",
    "        )\n",
    "\n",
    "        # Calculate non-zero monthly observation counts across all years\n",
    "        non_zero_monthly_counts = df[df['Streamflow (m3/s)'] > 0]['Month'].value_counts().reindex(\n",
    "            [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], fill_value=0\n",
    "        )\n",
    "\n",
    "        # Extract the filename as the gauge ID\n",
    "        gauge_id = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "        # Return the summary statistics\n",
    "        summary = {\n",
    "            \"Gauge ID\": gauge_id,\n",
    "            \"First Measurement Date\": first_date,\n",
    "            \"Last Measurement Date\": last_date,\n",
    "            \"Number of Possible Days\": num_possible_days,\n",
    "            \"Number of Daily Measurements\": num_daily_measurements,\n",
    "            \"% Missing\": percent_missing,\n",
    "            \"Average Flow (m3/s)\": average_flow,\n",
    "            \"Min Flow (m3/s)\": min_flow,\n",
    "            \"Max Flow (m3/s)\": max_flow,\n",
    "            **monthly_counts.add_suffix(\" (Total)\").to_dict(),\n",
    "            **non_zero_monthly_counts.add_suffix(\" (Non-Zero)\").to_dict()\n",
    "        }\n",
    "\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main function to process specific files based on gauge IDs and save the result\n",
    "def analyze_files_by_gauge_ids(folder_path, gauge_file, output_file):\n",
    "    try:\n",
    "        # Read the gauge IDs from the CSV file\n",
    "        gauge_data = pd.read_csv(gauge_file)\n",
    "        gauge_ids = set(gauge_data['gauge_id'].astype(str))\n",
    "\n",
    "        # List all CSV files in the folder\n",
    "        csv_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "        # Filter files that match the gauge IDs\n",
    "        matching_files = [file for file in csv_files if os.path.splitext(os.path.basename(file))[0] in gauge_ids]\n",
    "\n",
    "        # Wrap file processing with tqdm for a progress bar\n",
    "        results = Parallel(n_jobs=-1)(\n",
    "            delayed(process_specific_file)(file) for file in tqdm(matching_files, desc=\"Processing Files\")\n",
    "        )\n",
    "\n",
    "        # Filter out None results\n",
    "        results = [res for res in results if res is not None]\n",
    "\n",
    "        if results:\n",
    "            # Convert the results to a DataFrame for saving\n",
    "            summary_df = pd.DataFrame(results)\n",
    "            summary_df.to_csv(output_file, index=False)\n",
    "            print(f\"Summary file saved to {output_file}\")\n",
    "        else:\n",
    "            print(\"No valid data to process.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "\n",
    "# Specify the folder path, gauge file, and output file\n",
    "folder_path = \"/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/gauge_data\"  # Replace with the path to your folder containing CSV files\n",
    "gauge_file = \"/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/gauge_table_2nd_iteration_deDuplicated.csv\"  # Replace with the path to your gauge file\n",
    "output_file = \"/Users/yubinbaaniya/Documents/GAUGE REVIEW/summary_only_gauge_used.csv\"  # Replace with your desired output path\n",
    "\n",
    "# Run the processing\n",
    "analyze_files_by_gauge_ids(folder_path, gauge_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
